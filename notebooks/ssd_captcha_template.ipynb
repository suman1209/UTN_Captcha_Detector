{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98ee10b8-389a-4787-82c1-4277b7b7c559",
   "metadata": {},
   "source": [
    "# Configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "934d956e-e7b0-4e6f-8a46-45fe77badfdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 3\n",
    "## other standard packages\n",
    "import os\n",
    "import sys\n",
    "## Env variables and preparation stuffs\n",
    "sys.path.insert(0, \"../\")\n",
    "from src_code.task_utils.config_parser import ConfigParser\n",
    "configs_dict = {\n",
    "    \"data_configs\": {\n",
    "        \"train_path\": \"datasets/utn_dataset_curated/part2/train\",\n",
    "        \"val_path\": \"datasets/utn_dataset_curated/part2/val\",\n",
    "        \"test_path\": \"datasets/utn_dataset_curated/part2/test\",\n",
    "        \"preprocessing\": {\n",
    "            \"mean\": 0.5,  # for raw_image normalisation\n",
    "            \"std\": 0.5,  # for raw_image normalisation\n",
    "            \"downscale_factor\": 4,\n",
    "        },\n",
    "        \"augmentation_related\": {\n",
    "            \"place_holder\": None,  # this is just a place holder, will be filled later\n",
    "        },\n",
    "    },\n",
    "    \"model_configs\": {\n",
    "        \"epochs\": 1,\n",
    "        \"batch_size\": 32,\n",
    "        \"device\": \"cuda\",  # either \"cpu\" or \"cuda\"\n",
    "        \"backbone\": {\n",
    "            \"name\": \"VGG16\",\n",
    "            \"num_stages\": 6,\n",
    "        },\n",
    "        \"loss\": {\n",
    "            \"alpha\": 1,  # loss = alpha*loc_loss + cls_loss\n",
    "            \"pos_box_threshold\": 0.5,  # a default box is marked positive if it has (> pos_box_threshold) IoU score with any of the groundtruth boxes\n",
    "            \"hard_neg_pos\": 3,  # num of negative boxes = hard_neg_pos * num_positive_boxes\n",
    "        },\n",
    "        \"optim\": {\n",
    "            \"name\": \"SGD\",\n",
    "            \"lr\": 0.001,\n",
    "            \"momentum\": 0.9,\n",
    "            \"weight_decay\": 0.0005,\n",
    "        },\n",
    "        \"scheduler\": {\n",
    "            \"name\": \"MultiStepLR\",\n",
    "            \"milestones\": [155, 195],\n",
    "            \"gamma\": 0.1,\n",
    "        },\n",
    "    },\n",
    "    \"task_configs\": {\n",
    "        \"img_height\": 160,  # original image height\n",
    "        \"img_width\": 640,  # original image width\n",
    "        \"debug\": True,  # if True will display a lot of intermediate information for debugging purposes\n",
    "        \"log_expt\": False,  # whether to log the experiment online or not\n",
    "        \"num_classes\": 37,  # A-Z(26), 0-9(10), background(1)\n",
    "        \"min_cls_score\": 0.01,  # if the cls score for a bounding box is less than this, it is considered as background\n",
    "        \"nms_iou_score\": 0.1,  # if the iou between two bounding boxes is less than this, it is suppressed\n",
    "    },\n",
    "}\n",
    "# hyperparameters\n",
    "preprocessed_dir = \"../datasets/utn_dataset_curated/part2/test/preprocessed\"\n",
    "labels_dir = \"../datasets/utn_dataset_curated/part2/train/labels\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41000c80-0aee-4d58-9fad-11a4c2344aa8",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "16d1639a-4f80-4cbe-aa48-da4f30787063",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2234bd15-102f-427f-92c7-76aa39894f61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "config = {'data_configs': {'train_path': 'datasets/utn_dataset_curated/part2/train', 'val_path': 'datasets/utn_dataset_curated/part2/val', 'test_path': 'datasets/utn_dataset_curated/part2/test', 'preprocessing': {'mean': 0.5, 'std': 0.5, 'downscale_factor': 4}, 'augmentation_related': {'place_holder': None}}, 'model_configs': {'epochs': 1, 'batch_size': 32, 'device': 'cuda', 'backbone': {'name': 'VGG16', 'num_stages': 6}, 'loss': {'alpha': 1, 'pos_box_threshold': 0.5, 'hard_neg_pos': 3}, 'optim': {'name': 'SGD', 'lr': 0.001, 'momentum': 0.9, 'weight_decay': 0.0005}, 'scheduler': {'name': 'MultiStepLR', 'milestones': [155, 195], 'gamma': 0.1}}, 'task_configs': {'img_height': 160, 'img_width': 640, 'debug': True, 'log_expt': False, 'num_classes': 37, 'min_cls_score': 0.01, 'nms_iou_score': 0.1}}\n",
      "config.pos_box_threshold = 0.5\n"
     ]
    }
   ],
   "source": [
    "config = ConfigParser(configs_dict).get_parser()\n",
    "# this object can be used as follows:\n",
    "print(f\"{config.pos_box_threshold = }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a0ffc95-8219-423d-89e4-a5fc4dbbe8c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# note: change to relative import using a dot (.) in datautils line 4 & 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebe0cb7d-b2d9-466b-81d9-dec4f9ae9974",
   "metadata": {},
   "source": [
    "# 0. Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ded66662-0ef2-48a9-adda-6e2ace0d8c53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['../', 'C:\\\\Program Files\\\\WindowsApps\\\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\\\python311.zip', 'C:\\\\Program Files\\\\WindowsApps\\\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\\\DLLs', 'C:\\\\Program Files\\\\WindowsApps\\\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\\\Lib', 'C:\\\\Program Files\\\\WindowsApps\\\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0', '', 'C:\\\\Users\\\\irene\\\\AppData\\\\Local\\\\Packages\\\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\\\LocalCache\\\\local-packages\\\\Python311\\\\site-packages', 'C:\\\\Users\\\\irene\\\\AppData\\\\Local\\\\Packages\\\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\\\LocalCache\\\\local-packages\\\\Python311\\\\site-packages\\\\win32', 'C:\\\\Users\\\\irene\\\\AppData\\\\Local\\\\Packages\\\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\\\LocalCache\\\\local-packages\\\\Python311\\\\site-packages\\\\win32\\\\lib', 'C:\\\\Users\\\\irene\\\\AppData\\\\Local\\\\Packages\\\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\\\LocalCache\\\\local-packages\\\\Python311\\\\site-packages\\\\Pythonwin', 'C:\\\\Program Files\\\\WindowsApps\\\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\\\Lib\\\\site-packages']\n",
      "Image Shape: torch.Size([1, 32, 100])\n",
      "Bounding Boxes: tensor([[ 0.0358,  0.1204,  0.0500,  0.2146],\n",
      "        [ 0.0827, -0.0028,  0.1153,  0.1276],\n",
      "        [ 0.1045,  0.0661,  0.1364,  0.1926],\n",
      "        [ 0.1936,  0.0773,  0.2194,  0.2038]])\n",
      "Labels: tensor([21,  3, 24,  4])\n",
      "Batch Image Shape: torch.Size([4, 1, 32, 100])\n",
      "Bounding Boxes (First Image): tensor([[0.0233, 0.0585, 0.0572, 0.1957],\n",
      "        [0.1159, 0.0775, 0.1405, 0.1973],\n",
      "        [0.1866, 0.0304, 0.2237, 0.1797]])\n",
      "Labels (First Image): tensor([34,  6, 34])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\irene\\Documents\\UTN\\CV\\groupAssignment\\code\\UTN_Captcha_Detector\\notebooks\\..\\src_code\\data_utils\\dataset_utils.py:112: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  image = torch.load(preprocessed_path)\n"
     ]
    }
   ],
   "source": [
    "print(sys.path)\n",
    "from src_code.data_utils.dataset_utils import CaptchaDataset, get_dataloader\n",
    "from src_code.data_utils.augmentation import Augmentations\n",
    "# if the preprocessed dataset is not available, run create it using src_code/data_utils/preprocessing.py\n",
    "\n",
    "# Create dataset\n",
    "dataset = CaptchaDataset(preprocessed_dir, labels_dir, downscale_factor=4, augment=True)\n",
    "\n",
    "# Load a sample\n",
    "image, bboxes, labels = dataset[0]\n",
    "\n",
    "print(\"Image Shape:\", image.shape)\n",
    "print(\"Bounding Boxes:\", bboxes)\n",
    "print(\"Labels:\", labels)\n",
    "\n",
    "\n",
    "# Create DataLoader\n",
    "dataloader = get_dataloader(dataset, batch_size=4, shuffle=True)\n",
    "\n",
    "# Load a single batch\n",
    "images, bboxes, labels = next(iter(dataloader))\n",
    "\n",
    "# Print batch info\n",
    "print(f\"Batch Image Shape: {images.shape}\")\n",
    "print(f\"Bounding Boxes (First Image): {bboxes[0]}\")\n",
    "print(f\"Labels (First Image): {labels[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd0ac567-c663-4d04-a301-c4e2b1ff9f8b",
   "metadata": {},
   "source": [
    "# 1. Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a48a56e",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Move model to the appropriate device\u001b[39;00m\n\u001b[0;32m      7\u001b[0m device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_configs\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m----> 8\u001b[0m \u001b[43mssd_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1340\u001b[0m, in \u001b[0;36mModule.to\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1337\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1338\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[1;32m-> 1340\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\module.py:900\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn, recurse)\u001b[0m\n\u001b[0;32m    898\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[0;32m    899\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[1;32m--> 900\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    902\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[0;32m    903\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[0;32m    904\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[0;32m    905\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    910\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[0;32m    911\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\module.py:900\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn, recurse)\u001b[0m\n\u001b[0;32m    898\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[0;32m    899\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[1;32m--> 900\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    902\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[0;32m    903\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[0;32m    904\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[0;32m    905\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    910\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[0;32m    911\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\module.py:900\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn, recurse)\u001b[0m\n\u001b[0;32m    898\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[0;32m    899\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[1;32m--> 900\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    902\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[0;32m    903\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[0;32m    904\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[0;32m    905\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    910\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[0;32m    911\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\module.py:927\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn, recurse)\u001b[0m\n\u001b[0;32m    923\u001b[0m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[0;32m    924\u001b[0m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[0;32m    925\u001b[0m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[0;32m    926\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m--> 927\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    928\u001b[0m p_should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[0;32m    930\u001b[0m \u001b[38;5;66;03m# subclasses may have multiple child tensors so we need to use swap_tensors\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1326\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m   1319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m):\n\u001b[0;32m   1320\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(\n\u001b[0;32m   1321\u001b[0m             device,\n\u001b[0;32m   1322\u001b[0m             dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1323\u001b[0m             non_blocking,\n\u001b[0;32m   1324\u001b[0m             memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format,\n\u001b[0;32m   1325\u001b[0m         )\n\u001b[1;32m-> 1326\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1327\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1328\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_floating_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1329\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1330\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1331\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   1332\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e) \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot copy out of meta tensor; no data!\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\cuda\\__init__.py:310\u001b[0m, in \u001b[0;36m_lazy_init\u001b[1;34m()\u001b[0m\n\u001b[0;32m    305\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    306\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot re-initialize CUDA in forked subprocess. To use CUDA with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    307\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultiprocessing, you must use the \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspawn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m start method\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    308\u001b[0m     )\n\u001b[0;32m    309\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(torch\u001b[38;5;241m.\u001b[39m_C, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_cuda_getDeviceCount\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 310\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTorch not compiled with CUDA enabled\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    311\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _cudart \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    312\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\n\u001b[0;32m    313\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlibcudart functions unavailable. It looks like you have a broken build?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    314\u001b[0m     )\n",
      "\u001b[1;31mAssertionError\u001b[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "from src_code.model_utils.ssd import SSD300\n",
    "\n",
    "# Instantiate the SSD model with grayscale input\n",
    "ssd_model = SSD300(num_classes=config['task_configs']['num_classes'])\n",
    "\n",
    "# Move model to the appropriate device\n",
    "# device = torch.device(config['model_configs']['device'])  # CUDA\n",
    "device = torch.device('cpu')  # Troubles with CUDA, using CPU\n",
    "ssd_model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f44d19ab-526e-4e66-a4f7-7d0eb73c92fb",
   "metadata": {},
   "source": [
    "## 1.1 Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ffd9537",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'num_classes'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m SSD300(num_classes\u001b[38;5;241m=\u001b[39m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_classes\u001b[49m, in_channels\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel loaded on \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdevice\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'dict' object has no attribute 'num_classes'"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "\n",
    "# Display model summary\n",
    "summary(ssd_model, input_size=(1, 300, 300))  # Grayscale input: 1 channel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b20d6389-fe7a-4df7-82bd-9e98ead66501",
   "metadata": {},
   "source": [
    "## 1.2 Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f044187b-ba69-4376-b2a3-3caf57388979",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src_code.model_utils.loss import MultiBoxLoss\n",
    "default_boxes = torch.Tensor([[0.5000, 0.1250, 0.5000, 0.1250],[0.5000, 0.3750, 0.5000, 0.1250],\n",
    "        [0.5000, 0.6250, 0.5000, 0.1250],[0.5000, 0.8750, 0.5000, 0.1250],\n",
    "        [0.5000, 0.1250, 0.5000, 0.0625],[0.5000, 0.3750, 0.5000, 0.0625],\n",
    "        [0.5000, 0.6250, 0.5000, 0.0625],[0.5000, 0.8750, 0.5000, 0.0625]])\n",
    "# (1, 8, 4)\n",
    "locs_pred = torch.Tensor([[[0., 0., 0., 0.],\n",
    "                     [0., 0., 0., 0.],\n",
    "                     [0., 0., 0., 0.],\n",
    "                     [0., 0., 0., 0.],\n",
    "                     [0., 0., 0., 0.],\n",
    "                     [0., 0., 0., 0.],\n",
    "                     [0., 0., 0., 0.],\n",
    "                     [0., 0., 0., 0.]]])\n",
    "\n",
    "# (1, 8, 36)\n",
    "cls_pred = torch.Tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
    "      0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
    "      0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.9000, 0.0000, 0.0000,\n",
    "      0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
    "      0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
    "     [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
    "      0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
    "      0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
    "      0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
    "      0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
    "     [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
    "      0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
    "      0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.9000, 0.0000, 0.0000,\n",
    "      0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
    "      0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
    "     [0.0000, 0.0000, 0.0000, 0.0000, 0.9000, 0.0000, 0.0000, 0.0000,\n",
    "      0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
    "      0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
    "      0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
    "      0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
    "     [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
    "      0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
    "      0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.9000, 0.0000, 0.0000,\n",
    "      0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
    "      0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
    "     [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
    "      0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
    "      0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
    "      0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
    "      0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
    "     [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
    "      0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
    "      0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.9000, 0.0000, 0.0000,\n",
    "      0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
    "      0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
    "     [0.0000, 0.0000, 0.0000, 0.0000, 0.9000, 0.0000, 0.0000, 0.0000,\n",
    "      0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
    "      0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
    "      0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
    "      0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
    "boxes = torch.Tensor([[[ 61,  36, 139, 115], [297,  10, 386,  98], [509,  26, 572,  90]]])\n",
    "labels = torch.Tensor([[21,  0, 33]])\n",
    "\n",
    "# calculate loss\n",
    "mbl = MultiBoxLoss(default_boxes, config)\n",
    "loss, debug_info = mbl(locs_pred, cls_pred, boxes, labels)\n",
    "expected_loss = 10.8635"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "29716e21-60a9-4382-b9ae-8fbab55fe563",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(291.2195)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8bd0c178-b35c-4d61-ad64-0e103d358d56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'overlap_gt_def_boxes': [tensor([[0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0.]])],\n",
       " 'db_for_each_obj': [tensor([0, 0, 0])],\n",
       " 'db_indices_for_each_obj': [tensor([0, 0, 0])],\n",
       " 'overlap_value_for_each_db': tensor([1., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'self.label_each_db': [tensor([33., 36., 36., 36., 36., 36., 36., 36.])],\n",
       " 'match': [tensor([ True, False, False, False, False, False, False, False])],\n",
       " 'gt_locs': [tensor([[  19.0000, 1071.0000,    5.8158,   12.6685],\n",
       "          [  27.7500,  170.0000,    6.8686,   13.7364],\n",
       "          [  27.7500,  150.0000,    6.8686,   13.7364],\n",
       "          [  27.7500,  130.0000,    6.8686,   13.7364],\n",
       "          [  27.7500,  380.0000,    6.8686,   17.2021],\n",
       "          [  27.7500,  340.0000,    6.8686,   17.2021],\n",
       "          [  27.7500,  300.0000,    6.8686,   17.2021],\n",
       "          [  27.7500,  260.0000,    6.8686,   17.2021]]),\n",
       "  tensor([[  19.0000, 1071.0000,    5.8158,   12.6685],\n",
       "          [  27.7500,  170.0000,    6.8686,   13.7364],\n",
       "          [  27.7500,  150.0000,    6.8686,   13.7364],\n",
       "          [  27.7500,  130.0000,    6.8686,   13.7364],\n",
       "          [  27.7500,  380.0000,    6.8686,   17.2021],\n",
       "          [  27.7500,  340.0000,    6.8686,   17.2021],\n",
       "          [  27.7500,  300.0000,    6.8686,   17.2021],\n",
       "          [  27.7500,  260.0000,    6.8686,   17.2021]])],\n",
       " 'num_images': 1,\n",
       " 'loc_loss': tensor(276.6211),\n",
       " 'n_positive': tensor([1]),\n",
       " 'n_hard_negatives': tensor([3]),\n",
       " 'gt_label_each_default_box': tensor([33, 36, 36, 36, 36, 36, 36, 36]),\n",
       " 'conf_loss_for_each_default_box': tensor([[3.6496, 3.6109, 3.6496, 3.6496, 3.6496, 3.6109, 3.6496, 3.6496]]),\n",
       " 'confidence_pos_loss': tensor([[3.6496, 3.6109, 3.6496, 3.6496, 3.6496, 3.6109, 3.6496, 3.6496]]),\n",
       " 'hard_negatives': tensor([[ True,  True,  True, False, False, False, False, False]]),\n",
       " 'conf_neg_loss': tensor([[3.6496, 3.6109, 3.6496, 3.6496, 3.6496, 3.6109, 3.6496, 3.6496]]),\n",
       " 'ce_loss': tensor(14.5984),\n",
       " 'ce_hard_neg_loss': tensor(10.9488),\n",
       " 'ce_pos_loss': tensor(3.6496),\n",
       " 'loss': tensor(291.2195)}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "debug_info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c44dd71d-fcde-495d-bfda-a326f44eba56",
   "metadata": {},
   "source": [
    "# 2. Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eddccfc6-5820-4c8c-9e14-5262389d34ac",
   "metadata": {},
   "source": [
    "# 3. Evaluation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
